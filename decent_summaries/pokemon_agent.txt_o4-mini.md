The SimpleAgent module implements a self-driving, game-playing agent that binds an emulator with multiple LLM backends (Anthropic Claude, Google Gemini, OpenAI) and spatial-mapping utilities to explore and navigate game worlds autonomously. It relies on standard Python libraries (e.g. base64, threading, PIL, NumPy) plus project-specific configs (model names, token limits, navigation flags), emulator/tool definitions, prompt utilities, and API keys. LLM clients are initialized on import, the root logger is set to INFO, and image sizing and token limits are configured up front.

At its core is the LocationCollisionMap, a player-centered grid where each tile is marked unknown (–1), wall (0), open (1), sprite (2) or player (3). As the agent moves, update_map pads or resizes this grid, updates tile states, and runs a breadth-first search to maintain minimum-step distances. A backtrace over these distances yields directional step sequences via generate_buttons_to_coord, and two ASCII exporters—one machine-parsable, one human-friendly—provide both log and model inputs.

SimpleAgent’s constructor spins up the emulator (headless optional), attaches each LLM client, and optionally loads prior state and location archives. It allocates histories for gameplay and navigation, archives of visited coordinates and user labels, per-location collision maps, exploration milestones, checkpoints, and a circular TextDisplay buffer. All tool calls—press_buttons, navigate_to, offscreen navigation and others—are funneled through process_tool_call, which formats inputs per API, invokes the correct handler, logs each action, and rejects unknown tools with an error message.

press_buttons logs and issues button sequences to the emulator, updates player coordinates, the collision map, and visit history, and returns text feedback plus optional annotated screenshots and ASCII maps. navigate_to computes an in-map path, backtracks it into button presses, steps through each move, captures a post-move screenshot, and packages a detailed tool_result. For offscreen targets, navigate_to_offscreen_coordinate reads emulator memory and the full collision map to check reachability, then either issues direct button presses or queries the LLM for a text-based route, parses its response, and delegates execution to press_buttons.

Users can label specific coordinates or overwrite them via bookmark_location_or_overwrite_label, and mark_checkpoint resets step counters, deactivates tracking, records achievements, and logs confirmations. A dedicated detailed_navigator mode isolates fine-grained exploration, spawning its own message histories and system instructions for Claude/OpenAI loops. All of these mutable structures—label_archive, location_history, message logs, collision maps, checkpoints, and navigator flags—are pickled by save_location_archive and rehydrated by load_location_archive, which also strips legacy, non-text tool entries and prunes embedded images or “[TEXT_MAP]…[/TEXT_MAP]” blocks to conserve tokens.

Visual feedback is generated by get_screenshot_base64, which captures and optionally upscales the emulator screen, overlays a grid annotated with coordinates, passability flags, exploration status, visit recency, checkpoint markers, and NPC icons, then saves a debug PNG and returns its base64 encoding. update_and_get_full_collision_map similarly fetches and downsamples raw collision data, updates or creates the per-location map, and returns its ASCII form.

The run(num_steps,…) method drives the main loop: an optional background updater thread is launched; emulator state is initialized or restored; and for each step it updates milestones, encodes annotated screenshots, chooses between normal or detailed navigator prompts (omitting embedded images where appropriate), invokes the designated LLM, parses its streamed response into reasoning, tool calls, and outputs, and executes them via process_tool_call—automatically asking “Can you please continue playing the game?” if none are found. It enforces per-mode/model history limits, toggles navigation modes, resets labels at thresholds, saves state and milestones periodically (and on shutdown), logs progress, handles interrupts, and ultimately stops the emulator, returning the total steps executed.

Under the hood, prompt_text_reply builds chat-style message arrays (with optional history and a base64 screenshot), dispatches requests to Claude, Gemini or OpenAI, streams and concatenates their chunked replies, and gracefully handles errors (e.g. safety refusals). The agentic_summary routine periodically compiles a compact world summary: it dumps RAM/memory info, location data, recent checkpoints and labels, and either builds or retrieves a combat-aware ASCII map, then issues three successive LLM calls (facts extraction, cleanup, summarization), logs each stage, writes to “agentic_summary.txt,” captures a fresh annotated screenshot, and replaces the main message histories with this distilled summary plus image for further play. Finally, a stop() method halts the run loop and emulator, and a __main__ entrypoint binds everything together for a scripted ten-step demo with cleanup on KeyboardInterrupt.
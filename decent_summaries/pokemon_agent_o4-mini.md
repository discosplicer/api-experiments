This code implements SimpleAgent, a Python-based controller that uses large language models to play a ROM (by default “pokemon.gb”) via a headless emulator. At startup it imports standard libraries (e.g. base64, io, threading, pickle), NumPy, PIL, LLM clients (Anthropic Claude, Google Gemini, OpenAI), and several custom modules (configuration, prompts, emulator interface, tool definitions, utilities, secret API keys). A set of constants defines image sizes, model names, token limits, temperature, a direct-navigation flag, save intervals and related thresholds.

Core functionality centers on a player-centered grid map (LocationCollisionMap) that merges collision and sprite data into a small integer grid (–1 unknown, 0 wall, 1 passable, 2 sprite, 3 player), computes BFS distances, back-traces paths into up/down/left/right button sequences, and renders ASCII maps for logging. A TextDisplay class maintains a rolling buffer of recent messages, echoing them to console and to disk. Utility functions fetch and down-sample raw collision data into full maps or return stored tile labels.

To inform LLMs visually, get_screenshot_base64 captures a PIL screenshot (optionally upscaled), overlays gridlines, annotates each tile in a 9×10 grid with passability flags and sprites, adjusts font sizes per model, saves a test.png, and returns a base64-encoded PNG. SimpleAgent’s constructor configures the emulator (ROM path, sound/headless, optional main thread), optionally restores a saved emulator state and archived locations, and instantiates LLM clients according to MODEL and MAPPING_MODEL settings.

Internally, SimpleAgent tracks two message histories (standard and navigation), per-location visitation flags and custom labels, a map of LocationCollisionMaps, a global set of visited locations and recorded milestones, checkpoints, multiple step counters, and an embedded TextDisplay. It supports full state persistence via pickle (save_location_archive/load_location_archive), handling backward compatibility and pruning malformed entries, and history pruning routines collapse older messages and embedded images to conserve tokens.

The run() method—optionally in a background thread—loops up to num_steps: advancing the emulator frame, polling game state (location, coordinates, RAM), logging arrivals, updating visitation flags, and deciding between “standard” or “detailed navigator” modes. In standard mode it sends concise system prompts and minimal context; in detailed mode it captures high-resolution screenshots, full ASCII maps, trims old navigation messages, and marks recent user messages as ephemeral. MODEL-specific dispatch handles prompts and API calls:

• Claude (Anthropic) uses system or full-navigator prompts with a tool list and logs token usage.  
• Gemini (Google) uses the chat API with retries, then extracts tool calls.  
• OpenAI uses function-call mode, injecting memory dumps, nearby labels, screenshots, checkpoints, and optional text maps.

All workflows extract tool_call objects, feed them to process_tool_call for normalization and dispatch, then prune or summarize histories when they exceed size or token thresholds. If no tool calls are returned, the agent appends “Can you please continue playing the game?” to maintain progress.

Multiple step counters (total steps, steps since checkpoint, label reset, location shift) drive periodic behaviors: after 50 steps without a checkpoint it enables location tracking; if no movement occurs for 300+ steps (outside combat) it auto-enables detailed navigation; on location change it archives an “Entrance to X” label for the previous coordinates, resets counters, and disables detailed mode; after extended inactivity it clears non-approximate custom labels (200 steps for Claude, 1000 for other models). Every save_every steps—and at loop end—it persists state and writes location_milestones.txt. KeyboardInterrupt triggers a graceful stop, while other exceptions are logged and re-raised.

Tool handlers include press_buttons (executes a sequence of emulator button presses, logs memory/collision changes, updates histories, returns tool results), navigate_to (for on-screen targets, computes a path via emulator.find_path, iterates presses, captures fresh memory, base64 screenshot, ASCII map, updates state and returns rich results), and navigate_to_offscreen_coordinate (builds or LLM-augmented ASCII maps to navigate to off-screen coordinates, erroring if unreachable). Additional tools let the agent bookmark or overwrite location labels, mark checkpoints (resetting counters and recording milestones), provide navigation assistance (RAM, maps, labels, LLM-generated advice), enable detailed planning mode, or handle unknown tool calls with errors.

The prompt_text_reply helper abstracts messaging across models—optionally trimming history, embedding screenshots, and formatting API calls—then collects or streams responses and returns plain text. When message histories or token use exceed thresholds, agentic_summary collates recent RAM info, step counts, maps, checkpoints, labels, and previous summaries, then performs a three-stage summarization via successive LLM prompts (fact extraction, cleanup, final summary), writing intermediates and replacing histories with the condensed summary.

On startup OpenAI’s message history is seeded with a user entry summarizing the prior conversation, a directive to continue playing, and an embedded base64 screenshot. The stop() method halts the run loop and stops the emulator. A main block resolves the ROM path, instantiates SimpleAgent, and invokes run(num_steps=10) inside a try/except/finally that logs progress, handles interrupts, and ensures cleanup.